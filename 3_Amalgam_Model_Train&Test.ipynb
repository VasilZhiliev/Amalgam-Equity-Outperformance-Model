{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd95f158-3508-4c6f-8556-7adc713076e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import ttest_rel\n",
    "import matplotlib.ticker as mtick\n",
    "import utils\n",
    "import gc\n",
    "import importlib\n",
    "import numba\n",
    "from statsmodels.api import add_constant\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "numba.set_num_threads(8)\n",
    "importlib.reload(utils)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89517bdd-3e04-4d52-b37d-e6ef339692f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "firm_data_daily = pd.read_csv('data/firm_daily_returns_cleaned.csv', low_memory=False)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc50fa73-8420-4ac5-9b02-a20b0982eb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_merged_pctfluidshiftpct.csv')\n",
    "ff_data = pd.read_csv('data/ff5_data_daily.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d219d4-f7e6-470e-9e33-3e81a39bee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf2391-6595-4b5b-9b79-0bd5968aa1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_amalgam_vs_index(amalgam_returns, index_returns):\n",
    "    amalgam_returns.index = pd.to_datetime(amalgam_returns.index)\n",
    "    index_returns.index = pd.to_datetime(index_returns.index)\n",
    "\n",
    "    shared_index = amalgam_returns.index.intersection(index_returns.index)\n",
    "    tmp = pd.DataFrame({\n",
    "        'Amalgam': amalgam_returns.loc[shared_index],\n",
    "        'Index': index_returns.loc[shared_index]\n",
    "    })\n",
    "\n",
    "    tmp = tmp + 1\n",
    "    tmp = tmp.cumprod()\n",
    "\n",
    "    max_val = tmp.max().max()\n",
    "    yticks_vals = [1]\n",
    "    base = 2\n",
    "    while base <= max_val:\n",
    "        yticks_vals.append(base)\n",
    "        base *= 2\n",
    "\n",
    "    plt.figure(figsize=(10, 6))  \n",
    "    plt.plot(tmp.index, tmp['Amalgam'], label='Amalgam Model', linewidth=0.9)\n",
    "    plt.plot(tmp.index, tmp['Index'], label='Index', linewidth=0.9)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.yscale('log')\n",
    "    plt.yticks(yticks_vals, [f\"{int(y*100)}%\" for y in yticks_vals])\n",
    "    plt.title(\"Cumulative Performance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6636c0a0-45a4-4ee9-9852-fcf01a253f1d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ff_data['date'] = pd.to_datetime(ff_data['date'].astype(str), format='%Y%m%d')\n",
    "ff_data.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77dcf4e-2ed0-4f8a-aeb4-50122c2ebd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_data_daily = pd.read_csv('data/index_daily_returns.csv')\n",
    "index_data_daily['date'] = pd.to_datetime(index_data_daily['date'], dayfirst=True)\n",
    "index_data_daily = index_data_daily[index_data_daily['date'].dt.year >= 1980]\n",
    "index_data_daily = index_data_daily[index_data_daily['date'].dt.year <= 2025]\n",
    "index_data_daily.set_index('date', inplace=True)\n",
    "returns = pd.DataFrame()\n",
    "returns['VWTD_Index'] = index_data_daily['vwretd']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca9e282-aa6e-44ed-ba1e-332f3151762c",
   "metadata": {},
   "source": [
    "### Number of Observations, companies with MC =/> 50 million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebe1acf-8680-42d4-87d3-3e0eeeb8375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = df.query('y >= 1961')['y']\n",
    "sns.histplot(years, bins=years.nunique())\n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Firm-Quarter Observations')\n",
    "plt.gca().yaxis.set_major_formatter(mtick.FuncFormatter(lambda x, _: f'{int(x):,}'))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81360557-21a4-4b36-9ac5-56ffc9cc42b6",
   "metadata": {},
   "source": [
    "#### Modified Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009f659d-6217-4c2e-8df2-64f3d62d21d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GIND'] = df['GIND'].astype(\"category\")  \n",
    "features = [\n",
    "    'cop_at_pct', 'noa_gr1a_pct', 'saleq_gr1_pct', 'resff3_12_1_pct',\n",
    "    'seas_6_10an_pct', 'debt_me_pct', 'seas_6_10na_pct',\n",
    "    'zero_trades_252_pct', 'zero_trades_21_pct', 'cowc_gr1a_pct',\n",
    "    'nncoa_gr1a_pct', 'ocf_me_pct', 'turnover_126d_pct',\n",
    "    'rmax5_rvol_21d_pct', 'seas_11_15na_pct', 'o_score_pct', 'niq_at_pct',\n",
    "    'seas_20_16an_pct', 'ni_arl_pct', 'ivol_ff3_21d_pct', 'ni_me_pct',\n",
    "    'dsale_dinv_pct', 'ni_be_pct', 'noa_at_pct', 'firm_age_pct',\n",
    "    'mom_12_1_pct', 'nfna_grla_pct', 'at_me_pct', 'GIND'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c8f1f-fc14-476b-8ea0-704bc23d180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing RET or MC\n",
    "df = df.dropna(subset=['RET', 'MC']).copy()\n",
    "\n",
    "# RET percentile within GIND per quarter\n",
    "df['ret_pct_gind'] = (\n",
    "    df.groupby(['GIND', 'y', 'qtr'])['RET']\n",
    "    .transform(lambda x: x.rank(pct=True))\n",
    ")\n",
    "\n",
    "# Value-weighted RET percentile across all firms per quarter\n",
    "# First, compute RET percentiles across all firms (not GIND-specific)\n",
    "df['ret_pct_all'] = (\n",
    "    df.groupby(['y', 'qtr'])['RET']\n",
    "    .transform(lambda x: x.rank(pct=True))\n",
    ")\n",
    "\n",
    "# VWRETD_PCT per quarter\n",
    "vwretd_pct = (\n",
    "    df.groupby(['y', 'qtr'])\n",
    "    .apply(lambda g: (g['ret_pct_all'] * g['MC']).sum() / g['MC'].sum())\n",
    "    .rename('vwretd_pct')\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Merge back to df\n",
    "df = df.merge(vwretd_pct, on=['y', 'qtr'], how='left')\n",
    "\n",
    "#Step 3: Label assignment\n",
    "df['label'] = 0\n",
    "df.loc[(df['ret_pct_gind'] > 0.5) & (df['ret_pct_all'] > df['vwretd_pct']), 'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686a88d2-15df-4d67-b7d5-9b7d9fb6bb17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import XgboostRolling  \n",
    "\n",
    "df = df.replace([np.inf, -np.inf], np.nan) \n",
    "\n",
    "xgb_model = XgboostRolling(\n",
    "    data=df,\n",
    "    features=features,          \n",
    "    label='label',               \n",
    "    test_y_qtr_cut=(1981, 1),    \n",
    "    rolling_interval=1,           \n",
    "    last_y_qtr=(2024,4)\n",
    ")\n",
    "\n",
    "xgb_model.fit(tuning_method='sequential')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911ee588-4716-4c6a-bd20-8411ee29746e",
   "metadata": {},
   "source": [
    "### Save Model to directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d4dd69-accd-4589-8974-6d0191220738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"models/amalgam_xgb_roll\", exist_ok=True)\n",
    "for i, (y, q) in enumerate(xgb_model.lst_rolling_cut):\n",
    "    try:\n",
    "        model = xgb_model.models[i]\n",
    "        model.save_model(f\"models/amalgam_xgb_roll/xgb_{y}_{q}.json\")\n",
    "    except IndexError:\n",
    "        print(f\"No model trained for cut: {(y, q)} â€” skipping.\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cc7bc3-5d7a-4b9d-8c7a-c83792e47dd1",
   "metadata": {},
   "source": [
    "#### Predictions + Top Decile Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e49664-96df-4b46-88c3-782e58910b12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "testset = xgb_model.get_testset_with_prob()\n",
    "\n",
    "# Assign top decile label\n",
    "testset['ML_is_top_decile'] = testset.groupby(['y', 'qtr'])['prob'].transform(\n",
    "    lambda x: x >= x.quantile(0.9)\n",
    ")\n",
    "\n",
    "# Drop old Amalgam column if it exists\n",
    "if 'Amalgam' in firm_data_daily.columns:\n",
    "    firm_data_daily = firm_data_daily.drop(columns=['Amalgam'])\n",
    "\n",
    "# Merge testset into firm_data_daily\n",
    "merged_parts = []\n",
    "unique_quarters = firm_data_daily[['y', 'qtr']].drop_duplicates().sort_values(['y', 'qtr']).values.tolist()\n",
    "\n",
    "for y, q in unique_quarters:\n",
    "    firm_chunk = firm_data_daily[(firm_data_daily['y'] == y) & (firm_data_daily['qtr'] == q)]\n",
    "    test_chunk = testset[testset['y'].eq(y) & testset['qtr'].eq(q)][['y', 'qtr', 'PERMNO', 'ML_is_top_decile']]\n",
    "\n",
    "    merged = pd.merge(\n",
    "        firm_chunk,\n",
    "        test_chunk.rename(columns={'ML_is_top_decile': 'Amalgam'}),\n",
    "        on=['y', 'qtr', 'PERMNO'],\n",
    "        how='left'\n",
    "    )\n",
    "    merged_parts.append(merged)\n",
    "\n",
    "firm_data_daily = pd.concat(merged_parts, ignore_index=True)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df1955f-a610-4094-a1ac-429318894b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.to_csv('data/Amalgam_Top_Predictions.csv', index=False)\n",
    "firm_data_daily['Amalgam'] = firm_data_daily['Amalgam'].fillna(False)\n",
    "ML_returns = firm_data_daily[firm_data_daily['Amalgam']].groupby(['date'])['RET'].mean()\n",
    "plot_amalgam_vs_index(ML_returns, returns['VWTD_Index'])\n",
    "ML_returns.to_csv(\"data/Amalgam_Daily_Returns.csv\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0710fc55-0d89-44dd-8923-10746186908d",
   "metadata": {},
   "source": [
    "#### Bottom Decile + Top minus Bottom Decile Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a282d5-bb2e-4a16-92e3-a797ac66a382",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'testset' not in locals():\n",
    "    testset = xgb_model.get_testset_with_prob()\n",
    "\n",
    "# Identify bottom decile\n",
    "testset['ML_is_bottom_decile'] = testset.groupby(['y', 'qtr'])['prob'].transform(\n",
    "    lambda x: x <= x.quantile(0.1)\n",
    ")\n",
    "\n",
    "if 'Amalgam_Bottom' in firm_data_daily.columns:\n",
    "    firm_data_daily = firm_data_daily.drop(columns=['Amalgam_Bottom'])\n",
    "\n",
    "# Merge bottom decile into firm_data_daily\n",
    "merged_parts = []\n",
    "for y, q in firm_data_daily[['y', 'qtr']].drop_duplicates().values.tolist():\n",
    "    firm_chunk = firm_data_daily[(firm_data_daily['y'] == y) & (firm_data_daily['qtr'] == q)]\n",
    "    bottom_chunk = testset[testset['y'].eq(y) & testset['qtr'].eq(q)][['y', 'qtr', 'PERMNO', 'ML_is_bottom_decile']]\n",
    "\n",
    "    merged = pd.merge(\n",
    "        firm_chunk,\n",
    "        bottom_chunk.rename(columns={'ML_is_bottom_decile': 'Amalgam_Bottom'}),\n",
    "        on=['y', 'qtr', 'PERMNO'],\n",
    "        how='left'\n",
    "    )\n",
    "    merged_parts.append(merged)\n",
    "\n",
    "firm_data_daily = pd.concat(merged_parts, ignore_index=True)\n",
    "firm_data_daily['Amalgam_Bottom'] = firm_data_daily['Amalgam_Bottom'].fillna(False)\n",
    "\n",
    "# Calculate returns\n",
    "ML_top_returns = firm_data_daily[firm_data_daily['Amalgam']].groupby('date')['RET'].mean()\n",
    "ML_bottom_returns = firm_data_daily[firm_data_daily['Amalgam_Bottom']].groupby('date')['RET'].mean()\n",
    "ML_TMB_returns = ML_top_returns - ML_bottom_returns\n",
    "\n",
    "# Save\n",
    "ML_bottom_returns.to_csv(\"data/Amalgam_Bottom_Daily_Returns.csv\")\n",
    "ML_TMB_returns.to_csv(\"data/Amalgam_TopMinusBottom_Daily_Returns.csv\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4a3427-839a-4b15-8c66-f2985784103f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
